# les packages necessaires
install.packages("gbm")
install.packages("pROC")
library(gbm)
library(pROC)
#le fichier CSV
data <- read.csv("/framingham.csv")

# Split train test 
set.seed(123)  # Pour la reproductibilité
sample <- sample(c(TRUE,FALSE), nrow(data),replace=TRUE,prob=c(0.7,0.3))
trainData <- data[sample, ]
testData <- data[-sample, ]


# Gradient boosting avec la log-loss
gbm_model <- gbm(
  formula = TenYearCHD ~ .,
  data = trainData,
  distribution = "bernoulli",  # Log-loss pour la classification binaire
  n.trees = 100,               # Nombre d'arbres
  interaction.depth = 3,       # Profondeur d'interaction maximale
  shrinkage = 0.01,            # Taux d'apprentissage
  cv.folds = 5,                # Validation croisée avec 5 plis
  n.minobsinnode = 10,         # Nombre minimum d'observations dans les nœuds terminaux
  verbose = FALSE              
)

# Résumé du modèle
#summary(gbm_model)

# Prédiction sur les données de test
predictions <- predict(gbm_model, newdata = testData, n.trees = gbm_model$n.trees, type = "response")

# les prédictions en classes binaires
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

# performances et métriques du modèle
# Calcul dulog-loss
log_loss <- -mean(testData$TenYearCHD * log(predictions) + (1 - testData$TenYearCHD) * log(1 - predictions))
#la précision
accuracy <- mean(predicted_classes == testData$TenYearCHD)


# creation de la courbe ROC
roc_curve <- roc(testData$TenYearCHD, as.numeric(predictions))
auc_value <- auc(roc_curve)

# Tracer la courbe ROC
plot(roc_curve, main = "Courbe ROC de TenYearCHD")

# Affichage des métriques
print(paste("Log-Loss:", log_loss))
print(paste("Accuracy:", accuracy))
print(paste("AUC:", auc_value))
  
